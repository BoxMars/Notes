\documentclass{article}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx} 
\usepackage{float} 
\usepackage{fancyhdr}                                
\usepackage{lastpage}                                           
\usepackage{layout}   
\usepackage{subfigure} 
\pagestyle{fancy}  
\lhead{ZHANG HUAKANG}
\chead{Assignment 4} 
\rhead{DB92760} 
\renewcommand{\baselinestretch}{1.05}
\title{Assignment 4 of MATH 2005}
\author{ZHANG Huakang/DB92760}

\begin{document}
    \maketitle

    \section{}
        \paragraph{
            \begin{equation*}
                \begin{split}
                    E(X)=&\sum _{x=-1} ^3 xf(x)\\
                        =&-1\times \frac{3}{7} +0\times \frac{2}{7}+1\times \frac{1}{7}+2\times \frac{0}{7}+3\times \frac{1}{7}\\
                        =&\frac{1}{7}
                \end{split}
            \end{equation*}
        }

    \section{}  
        \paragraph{
            \begin{equation*}
                \begin{split}
                    E(X)=&\int _{-\infty} ^\infty yh(y) dy\\
                        =&\int _ 2 ^4 \frac{1}{8} (y+1)ydy +0\\
                        =&\frac{79}{3}
                \end{split}
            \end{equation*}
        }
    
    \section{}
        \subsection{}
                \begin{equation*}
                    \begin{split}
                        E(X)=&\int _{-\infty} ^\infty xf(x) dx\\
                            =&\int _1 ^3 x\frac{1}{x \log 3} dx + 0\\
                            =&\frac{2}{\log 3}\\
                    \end{split}
                \end{equation*}

                \begin{equation*}
                    \begin{split}
                        E(X^2)=&\int _{-\infty} ^\infty x^2f(x) dx\\
                            =&\int _1 ^3 \frac{x}{\log 3} dx\\
                            =&\frac{4}{\log 3}
                    \end{split}
                \end{equation*}

                \begin{equation*}
                    \begin{split}
                        E(X^3)=&\int _{-\infty} ^\infty x^3f(x) dx\\
                            =&\int _1 ^3 \frac{x^2}{\log 3} dx\\
                            =&\frac{26}{3\log 3}
                    \end{split}
                \end{equation*}

                \begin{equation*}
                    \begin{split}
                        E(X^3+2X^2-3X+1)=&E(X^3)+2E(X^2)-3E(X)+E(1)\\
                            =&\frac{26}{3\log 3}+2\times \frac{4}{\log 3} -3\times \frac{2}{\log 3}+1\\
                            =&\frac{35}{3\log3}
                    \end{split}
                \end{equation*}

        \subsection{}
            \begin{equation*}
                \begin{split}
                    \mu'_r=&E[X^r]\\
                        =&\int _{-\infty} ^\infty x^rf(x)dx\\
                        =&\int _1 ^3 x^r \frac{1}{x\log 3}dx\\
                        =&\frac{1}{\log 3}\int _1 ^3 x^{r-1} dx\\
                        =&\frac{1}{\log 3} \frac{1}{r}x^r|_1^3\\
                        =&\frac{1}{r\log 3}(3^r-1)
                \end{split}
            \end{equation*}

            \begin{equation*}
                \begin{split}
                    \sigma^2=&var(X)\\
                        =&E[X^2]-E[X]^2\\
                        =&\frac{4}{\log 3}-\frac{4}{\log 3 ^2}\\
                        =&\frac{4\log 3 -4}{\log 3 ^2}
                \end{split}
            \end{equation*}

    \section{}
        \begin{equation*}
            \begin{split}
                E(\frac{X}{Y})=&\int _0 ^1 \int _0 ^y \frac{x}{y}f(x,y) dx dy\\
                    =&\int _0 ^1 \int _0 ^y \frac{x}{y^2} dx dy\\
                    =&\int _0 ^1 \frac{x^2}{2y^2}|_0 ^y dy \\
                    =&\int _0 ^1 \frac{1}{2} dy\\
                    =& \frac{1}{2} y | _0 ^1 \\
                    =& \frac{1}{2} 
            \end{split}
        \end{equation*}
            
    \section{}
        \paragraph{
            Let $\varphi(x)$ is the money he should pay us where $x$ is the number we get from a balanced die.
            \begin{equation*}
                \begin{split}
                    E(\varphi(X))=&\sum _{x=1} ^6 \varphi(x)f(x)\\
                        =&\frac{1}{6}\sum_{x=1} ^4 \varphi(x)+\frac{10}{3}\\
                        =&0\\
                \end{split}
            \end{equation*}
            Thus, we can get,
            $$\sum _{x=1} ^4 \varphi(x)=-20$$
            which means that the total money we should pay that person when we roll a $1,2,3,$ or $4$ is equal to \$20. Hence, there are many solutions for this equation. For example,
            \begin{equation*}
                \begin{split}
                    \varphi(1)=\varphi(2)=\varphi(3)&=0,\\
                    \varphi(4)&=-20.
                \end{split}
            \end{equation*}
        }
    

    \section{}
        \subsection{}
            Let 
            \begin{equation*}
                \varphi(x;n)=
                \begin{cases}
                    x-(n-x)\times 0.4 & (0\leq x\leq n)\\
                    n& (n\leq x).
                \end{cases}
            \end{equation*}
            be the profit when produce $n$ cake(s) a day.

            \subsubsection*{(a) one of the cakes}
                \paragraph{
                    \begin{equation*}
                        \begin{split}
                            E(\varphi(X;1))=&\sum _{n=0} ^5 \varphi(x;1)f(x)\\
                                        =&\frac{1}{6}(-0.4+1+1+1+1+1)\\
                                        =&\frac{23}{30}
                        \end{split}
                    \end{equation*}
                }
            \subsubsection*{ (b) two of the cakes}
            \paragraph{
                \begin{equation*}
                    \begin{split}
                        E(\varphi(X;2))=&\sum _{n=0} ^5 \varphi(x;2)f(x)\\
                                    =&\frac{1}{6}(-0.8+0.6+2+2+2+2)\\
                                    =&1.2
                    \end{split}
                \end{equation*}
            }
            \subsubsection*{  (c) three of the cakes}
            \paragraph{
                \begin{equation*}
                    \begin{split}
                        E(\varphi(X;3))=&\sum _{n=0} ^5 \varphi(x;3)f(x)\\
                                    =&\frac{1}{6}(-1.2+0.2+1.6+3+3+3)\\
                                    =&1.6
                    \end{split}
                \end{equation*}
            }
            \subsubsection*{   (d) four of the cakes}
            \paragraph{
                \begin{equation*}
                    \begin{split}
                        E(\varphi(X;4))=&\sum _{n=0} ^5 \varphi(x;4)f(x)\\
                                    =&\frac{1}{6}(-1.6-0.2+1.2+2.6+4+4)\\
                                    =&\frac{5}{3}
                    \end{split}
                \end{equation*}
            }
            \subsubsection*{    (e) five of the cakes}
            \paragraph{
                \begin{equation*}
                    \begin{split}
                        E(\varphi(X;5))=&\sum _{n=0} ^5 \varphi(x;5)f(x)\\
                                    =&\frac{1}{6}(-2-0.6+0.8+2.2+3.6+5)\\
                                    =&\frac{3}{2}
                    \end{split}
                \end{equation*}
            }
        \subsection{}
            \paragraph{
                By $6.1$ we can know that he should bake 4 cakes a day to maximize his expected profit.
            }
    
    \section{}
            \begin{equation*}
                \begin{split}
                    E(Z)=&E(\frac{X-\mu}{\sigma})\\
                        =&\frac{1}{\sigma}(E(X-\mu))\\
                        =&\frac{1}{\sigma}(E(X)-E(\mu))\\
                        =&\frac{1}{\sigma}(\mu-\mu)\\
                        =&0
                \end{split}
            \end{equation*}

            \begin{equation*}
                \begin{split}
                    var(Z)=&E\{[Z-E(Z)]^2\}\\
                        =&E(Z^2)-[E(Z)]^2\\
                        =&E(Z^2)\\
                        =&E[(\frac{X-\mu}{\sigma} )^2]\\
                        =&\frac{1}{\sigma^2}E[(X-\mu)^2]\\
                        =&\frac{1}{\sigma^2}\times \sigma^2\\
                        =&1
                \end{split}
            \end{equation*}
    
    \section{}
        \paragraph{
            By Chebyshevs inequality, we can know that
            $$P(|X-\mu|<k\sigma)\geq 1-\frac{1}{k^2}$$
        }

        \subsection*{(a) at least 0.95}
            $$P(|X-\mu|<k\sigma)\geq 1-\frac{1}{k^2}\geq0.95$$
            $$k\geq 2\sqrt{5}$$
        
        \subsection*{(b) at least 0.99}
            $$P(|X-\mu|<k\sigma)\geq 1-\frac{1}{k^2}\geq0.99$$
            $$k\geq 10$$
    
    \section{}
  
            \begin{equation*}
                \begin{split}
                    P(64\leq X\leq 184)=&P(|X-\mu|\leq 60)\\
                        =&P(|X-\mu|\leq 8\sigma)\\
                        \geq&1-\frac{1}{8^2}=\frac{63}{64}
                \end{split}
            \end{equation*}
    
    \section{}
        \paragraph{
            From the table we can know that
            $$E(X)=\frac{1}{3}$$
            $$E(Y)=\frac{3}{4}$$
            Therefore,
        }
            \begin{equation*}
                \begin{split}
                    cov(X,Y)=&E(XY)-E(X)\times E(Y)\\
                        =&\sum_x \sum_y xyf(x,y)-\frac{1}{4}\\
                        =&\frac{1}{4}-\frac{1}{4}\\
                        =&0
                \end{split}
            \end{equation*}
        \paragraph{
            But, 
            \begin{equation*}
                \begin{split}
                    f(-1,0)=&0\\
                        \neq& g(-1)\times h(0)=\frac{1}{4}\times\frac{1}{4}=\frac{1}{16}
                \end{split}
            \end{equation*}
            where $g(x)$ and $h(y)$ are the marginal probability distribution of $X$ and $Y$, respectively.
        }

    \section{}
        \begin{equation*}
            \begin{split}
                var(X+Y)=&E[((X+Y)-E(X+Y))^2]\\
                    =&E[((X-E[X])+(Y-E[Y]))^2]\\
                    =&E[(X-E[X])^2]+E[(Y-E[Y])^2]\\
                        &+2E[(X-E[X])(Y-E[Y])]\\
                    =&var(X)+var(Y)+2cov(X,Y)
            \end{split}
        \end{equation*}

        \begin{equation*}
            \begin{split}
                var(X-Y)=&E[((X-Y)-E[X-Y])^2]\\
                    =&E[((X-E[X])-(Y-E[Y]))^2]\\
                    =&E[(X-E[X])^2]+E[(Y-E[Y])^2]\\
                        &-2E[(X-E[X])(Y-E[Y])]\\
                    =&var(X)+var(Y)-2cov(X,Y)
            \end{split}
        \end{equation*}

        \begin{equation*}
            \begin{split}
                cov(X+Y,X-Y)=&E[(X+Y)(X-Y)]-E[X+Y]\times E[X-Y]\\
                    =&E[X^2-Y^2]-(E[X]-E[Y])(E[X]+E[Y])\\
                    =&E[X^2]-E[Y^2]-E[X]^2+E[Y]^2\\
                    =&var(X)-var(Y)
            \end{split}
        \end{equation*}

    \section{}
        \subsection{}
            \begin{equation*}
                \begin{split}
                    E[U]=&E[2X-3Y+4Z]\\
                        =&2E[X]-3E[Y]+4E[Z]\\
                        =&-7
                \end{split}
            \end{equation*}

            \begin{equation*}
                \begin{split}
                    E[V]=&E[X+2Y-Z]\\
                        =&E[X]+2[Y]-E[Z]\\
                        =&19
                \end{split}
            \end{equation*}

            \begin{equation*}
                \begin{split}
                    var(U)=&var(2X-3Y+4Z)\\
                        =&var(2X)+var(-3Y)+var(4Z)\\
                        =&4var(X)+9var(Y)+16var(Z)\\
                        =&155
                \end{split}
            \end{equation*}

            \begin{equation*}
                \begin{split}
                    var(V)=&var(X+2Y-Z)\\
                        =&var(X)+4var(Y)+var(Z)\\
                        =&36
                \end{split}
            \end{equation*}


        \subsection{}
        \textit{Claim:}
            $$cov(X+Y,Z)=cov(X,Z)+cov(Y,Z)$$
           
        \begin{proof}
            \begin{equation*}
                \begin{split}
                    cov(X+Y,Z)=&E[(X+Y)Z]-E[X+Y]E[Z]\\
                        =&E[XZ+YZ]-(E[X]+E[Y])E[Z]\\
                        =&E[XZ]-E[X]E[Z]+E[YZ]-E[Y]E[Z]\\
                        =&cov(X,Z)+cov(Y,Z)
                \end{split}
            \end{equation*}
        \end{proof}

        \textit{Claim:}
            $$cov(nX,Y)=n\ cov(X,Y)$$
           where $n$ is a real number.
        \begin{proof}
            \begin{equation*}
                \begin{split}
                    cov(nX,Y)=&E[nXY]-E[nX]E[Y]\\
                        =&nE[XY]-nE[X]E[Y]\\
                        =&n(E[XY]-E[X]E[Y])\\
                        =&n\ cov(X,Y)
                \end{split}
            \end{equation*}
        \end{proof}
        It is easy to know that
        \begin{equation*}
            \begin{split}
                cov(aX,bY)=&a\ cov(X,bY)\\
                    =&ab\ cov(X,Y)
            \end{split}
        \end{equation*}

        \begin{equation*}
            \begin{split}
                var(U)=&var((2X-3Y)+4Z)\\
                    =&var(2X-3Y)+var(4Z)+2cov(2X-3Y,4Z)\\
                    =&var(2X-3Y)+var(4Z)+2cov(2X,4Z)+2cov(-3Y,4Z)\\
                    =&var(2X)+var(-3Y)+var(4Z)+16cov(X,Z)-24cov(Y,Z)\\
                    =&155
            \end{split}
        \end{equation*}

        \begin{equation*}
            \begin{split}
                var(V)=&var(X+2Y-Z)\\
                    =&var(X)+4var(Y)+var(Z)+2cov(X+2Y,-Z)\\
                    =&36+2cov(X,-Z)+2cov(2Y,-Z)\\
                    =&50
            \end{split}
        \end{equation*}

        \begin{equation*}
            \begin{split}
                E[U]=&E[2X-3Y+4Z]\\
                    =&2E[X]-3E[Y]+4E[Z]\\
                    =&-7
            \end{split}
        \end{equation*}

        \begin{equation*}
            \begin{split}
                E[V]=&E[X+2Y-Z]\\
                    =&E[X]+2[Y]-E[Z]\\
                    =&19
            \end{split}
        \end{equation*}
    
    \section{}
    We can get the joint probability distribution $f(z,w)$
    \textbf{ }\\

    \begin{tabular}{|c|c|c|}
        \hline        & $z=0$ & $z=1$ \\
        \hline  $w=0$ & $0.36$ & $0$\\
        \hline  $w=1$ & $0.24$ & $0.24$  \\
        \hline  $w=2$ & $0$ & $0.16$ \\
        \hline
    \end{tabular} 

    \textit{ }\\
    Thus, $$E[Z]=0.4$$
    $$E[W]=0.8$$
    \begin{equation*}
        \begin{split}
            cov(Z,W)=&E[ZW]-E[Z]E[W]\\
                =&\sum _z \sum _w zwf(z,w)-E[Z]E[W]\\
                =&-0.4
        \end{split}
    \end{equation*}
	
    \section{}
    The probability distribution $$f(x,y,z)=\frac{C_3 ^x C_2 ^y C _3 ^z}{C_8 ^2}$$
    where $x+y+z=2$ , $x$ is the number of statistics texts, $y$ is the number of mathematics texts and $z$ is the number of physics texts.
        \begin{equation*}
            \begin{split}
                E(Y;X=0)=&\sum _y yf(0,y,z)\\
                    =&\frac{2}{7}
            \end{split}
        \end{equation*}



\end{document}